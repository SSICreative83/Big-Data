{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pierre Navaro - [Institut de Recherche Mathématique de Rennes](https://irmar.univ-rennes1.fr) - [CNRS](http://www.cnrs.fr/)\n",
    "\n",
    "https://github.com/pnavaro/big-data/blob/master/02.Containers.ipynb\n",
    "\n",
    "[Display on nbviewer](http://nbviewer.jupyter.org/github/pnavaro/big-data/blob/master/02.Containers.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- All approaches in notebook 01 load all the data into memory. A very large file might fill up memory. \n",
    "- Counting words in each line is totally independent of the others. \n",
    "- We can evaluate each piece of data and immediately free up the memory space. \n",
    "- Data chunks would be small enough not to stress memory, but big enough for efficient use of the CPU.\n",
    "\n",
    "In this notebook we will see how to divide the load between different processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def words(file):\n",
    "    \"\"\" Read a text file and return a sorted list \n",
    "    of (word, 1) values.\n",
    "    \"\"\"\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    output = []\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            line = line.translate(translator)\n",
    "            for word in line.split():\n",
    "                word = word.lower()\n",
    "                output.append((word, 1))\n",
    "    output.sort()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def reduce(words):\n",
    "    \"\"\" Read the sorted list from map and print \n",
    "    out every word with its number of occurences\"\"\"\n",
    "    d = {}\n",
    "    for w in words:\n",
    "        try:\n",
    "            d[w[0]] +=1\n",
    "        except KeyError:\n",
    "            d[w[0]] = 1 \n",
    "    \n",
    "    return sorted(d.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('magnam', 20),\n",
       " ('modi', 18),\n",
       " ('sed', 16),\n",
       " ('sit', 15),\n",
       " ('aliquam', 14),\n",
       " ('amet', 14),\n",
       " ('porro', 14),\n",
       " ('non', 13),\n",
       " ('quisquam', 13),\n",
       " ('ut', 13),\n",
       " ('numquam', 12),\n",
       " ('quaerat', 12),\n",
       " ('quiquia', 12),\n",
       " ('etincidunt', 11),\n",
       " ('ipsum', 11),\n",
       " ('eius', 10),\n",
       " ('tempora', 10),\n",
       " ('dolor', 9),\n",
       " ('velit', 9),\n",
       " ('voluptatem', 9),\n",
       " ('adipisci', 7),\n",
       " ('est', 7),\n",
       " ('labore', 7),\n",
       " ('dolorem', 6),\n",
       " ('neque', 6),\n",
       " ('consectetur', 5),\n",
       " ('dolore', 4)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(words('sample.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Container datatypes\n",
    "\n",
    "`collection` module implements specialized container datatypes providing alternatives to Python’s general purpose built-in containers, `dict`, `list`, `set`, and `tuple`.\n",
    "\n",
    "- `namedtuple`\t: factory function for creating tuple subclasses with named fields\n",
    "- `deque`\t: list-like container with fast appends and pops on either end\n",
    "- `ChainMap`\t: dict-like class for creating a single view of multiple mappings\n",
    "- `Counter`\t: dict subclass for counting hashable objects\n",
    "- `defaultdict` :\tdict subclass that calls a factory function to supply missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Counter\n",
    "\n",
    "A Counter is a dict subclass for counting hashable objects. It is an unordered collection where elements are stored as dictionary keys and their counts are stored as dictionary values. Counts are allowed to be any integer value including zero or negative counts.\n",
    "\n",
    "Elements are counted from an iterable or initialized from another mapping (or counter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r': 23, 'g': 13, 'b': 23}\n",
      "0\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "violet = dict(r=23,g=13,b=23)\n",
    "print(violet)\n",
    "cnt = Counter(violet)  # or Counter(r=238, g=130, b=238)\n",
    "print(cnt['c'])\n",
    "print(cnt['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r r r r r r r r r r r r r r r r r r r r r r r g g g g g g g g g g g g g b b b b b b b b b b b b b b b b b b b b b b b\n"
     ]
    }
   ],
   "source": [
    "print(*cnt.elements())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('r', 23), ('b', 23)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([23, 13, 23])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 2.1\n",
    "\n",
    "Use a `Counter` object to count words occurences in a `text` produced by the `lorem` module. Hint: use the the `most_common` method of `Counter` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The Counter class is similar to bags or multisets in some Python libraries or other languages. We will see later how to use Counter-like objects in a parallel context. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Partition data\n",
    "\n",
    "In order to parallelize **reduce** operation, \n",
    "data must be aligned in a container. For this operation we will use the\n",
    "`dict` subclass `defaultdict`.\n",
    "\n",
    "![domain decomposition](https://computing.llnl.gov/tutorials/parallel_comp/images/domain_decomp.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## defaultdict\n",
    "\n",
    "This container is a `dict` subclass that calls a factory function to supply missing values.\n",
    "Using list as the default_factory, it is easy to group a sequence of key-value pairs into a dictionary of lists:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]\n",
    "d = defaultdict(list)\n",
    "for k, v in s:\n",
    "    d[k].append(v)\n",
    "\n",
    "sorted(d.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 2.2\n",
    "\n",
    "- Use `int` as default_factory instead of list in the example above. The second part of every item of the class will be an integer instead of a list. You must replace the `append` by the suitable operator.\n",
    "- Use the defaultdict for counting words in a text created by lorem module:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Exercise 2.3\n",
    "\n",
    "Create a function named `partition` that stores the key/value pairs from `words` (function created in notebook 01) into a `defaultdict` from `collections` module. Output will be:\n",
    "```python\n",
    "[('word1', [1, 1]), ('word2', [1]), ('word3', [1, 1, 1])]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 2.4\n",
    "- [itertools.chain(*mapped_values)](https://docs.python.org/3.6/library/itertools.html#itertools.chain) could be used for treating consecutive sequences as a single sequence. \n",
    "- [operator](https://docs.python.org/3.6/library/operator.html).itemgetter(1)\n",
    "Return a callable object that fetches item from its operand using the operand’s __getitem__() method. It could be used to sort results.\n",
    "```python\n",
    ">>> import itertools, operator\n",
    ">>> fruits = [('apple', 3), ('banana', 2), ('pear', 5), ('orange', 1)]\n",
    ">>> vegetables = [('endive', 2), ('spinach', 1), ('celery', 5), ('carrot', 4)]\n",
    ">>> getcount = operator.itemgetter(1)\n",
    ">>> print(list(map(getcount, itertools.chain(fruits,vegetables) )))\n",
    "[3, 2, 5, 1, 2, 1, 5, 4]\n",
    ">>> print(sorted(itertools.chain(fruits,vegetables), key=getcount))\n",
    "[('orange', 1), ('spinach', 1), ('banana', 2), ('endive', 2), ('apple', 3), ('carrot', 4), ('pear', 5), ('celery', 5)]\n",
    "```\n",
    "\n",
    "Write the program with the map, partition and reduce steps to compute\n",
    "the list of words with their number of occurences of files sample[0-7].txt \n",
    "created in notebook 01. Example of output:\n",
    "```python\n",
    "[('aliquam', 17),('voluptatem', 15),('tempora', 14),('sit', 13),\n",
    " ('quisquam', 13), ('non', 13),('eius', 13),('quiquia', 12), ('magnam', 12)]\n",
    " ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
