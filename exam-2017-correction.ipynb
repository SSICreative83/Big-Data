{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outils informatiques pour le \"big data\"\n",
    "\n",
    "## Contrôle du 14 décembre 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comptage de mots dans les traductions anglaises de 4 romans francais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons travailler avec les 4 textes des auteurs suivants\n",
    "\n",
    "- Victor Hugo http://www.gutenberg.org/files/135/135-0.txt\n",
    "- Marcel Proust http://www.gutenberg.org/files/7178/7178-8.txt\n",
    "- Emile Zola http://www.gutenberg.org/files/1069/1069-0.txt\n",
    "- Stendhal http://www.gutenberg.org/files/44747/44747-0.txt\n",
    "\n",
    "Pour ceux qui utilisent le proxy, téléchargez ces fichiers directement depuis votre navigateur. Sinon vous pouvez exécutez la cellule suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('books/stendhal.txt', <http.client.HTTPMessage at 0x7fb450d96550>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%mkdir -p books\n",
    "import urllib.request as url\n",
    "url.urlretrieve(\"http://www.gutenberg.org/files/135/135-0.txt\",     filename=\"books/hugo.txt\")\n",
    "url.urlretrieve(\"http://www.gutenberg.org/files/7178/7178-8.txt\",   filename=\"books/proust.txt\")\n",
    "url.urlretrieve(\"http://www.gutenberg.org/files/1069/1069-0.txt\",   filename=\"books/zola.txt\")\n",
    "url.urlretrieve(\"http://www.gutenberg.org/files/44747/44747-0.txt\", filename=\"books/stendhal.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liste de fichiers\n",
    "\n",
    "- Créer une liste `filenames` contenant les noms des fichiers contenant les text des 4 livres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "here = os.getcwd()\n",
    "filenames = sorted(glob.glob(os.path.join(here, 'books', '*.txt')))                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction `wordcount_map`\n",
    "\n",
    "- Coder une fonction nommée `wordcount_map` permettant de lire un fichier et de compter \n",
    "les mots transformés en minuscules et ne contenant que des lettres de l'alphabet.\n",
    "- Cette fonction renvoie un dictionnaire dont chaque mot du texte une clé et son\n",
    "nombre d'occurences la valeur corespondante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcount_map(textfile):\n",
    "                                     \n",
    "    with open(textfile,'r',encoding='latin-1') as f:\n",
    "       words = []\n",
    "       for line in f:\n",
    "          word_list = line.strip('\\n').strip('\\r').strip('.').strip(',').split(' ')\n",
    "          words.append([word.lower() for word in word_list if word.isalpha()])\n",
    "    \n",
    "    result = {}\n",
    "\n",
    "    for sentence in words:\n",
    "       for word in sentence:\n",
    "          try:\n",
    "             result[word] += 1 \n",
    "          except KeyError:\n",
    "             result[word] = 1\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec une boucle for, appliquer cette fonction sur la liste `filenames`.\n",
    "- Afficher le nombre de mots différents pour chaque livre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/pnavaro/big-data/books/hugo.txt',\n",
       " '/home/pnavaro/big-data/books/proust.txt',\n",
       " '/home/pnavaro/big-data/books/stendhal.txt',\n",
       " '/home/pnavaro/big-data/books/zola.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction `wordcount_reduce`\n",
    "\n",
    "- Coder une fonction avec comme argument une liste de dictionnaires calculés chacun par la fonction `wordcount_map` qui retourne un dictionnaire les mots apparaissant dans **tous** les livres avec leur nombre d'occurences total. \n",
    "\n",
    "- Ecrire le code et donner le nombre d'apparitions du mot `valjean` dans `les misérables`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def wordcount_reduce(dict_list):\n",
    "    result = {}\n",
    "    for d in dict_list:\n",
    "        for k, v in d.items():\n",
    "            try:\n",
    "                result[k] += v\n",
    "            except KeyError:\n",
    "                result[k] = v\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 401 ms, sys: 16.8 ms, total: 418 ms\n",
      "Wall time: 414 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import operator\n",
    "dict_list = [wordcount_map(filenames[0])] \n",
    "counts = wordcount_reduce(dict_list)\n",
    "result = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790\n"
     ]
    }
   ],
   "source": [
    "for mot, occurence in result:\n",
    "    if mot == 'valjean':\n",
    "        print(occurence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version sequentielle\n",
    "\n",
    "- Ecrire la boucle `for` qui permet de calculer les occurences des mots dans les 4 livres.\n",
    "- Afficher les 5 premiers mots les plus courants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 73863), ('of', 39701), ('to', 31788), ('and', 28780), ('a', 28284)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "mapped_values = []\n",
    "for f in filenames:\n",
    "   mapped_values.append(wordcount_map(f))\n",
    "\n",
    "result = wordcount_reduce(mapped_values)\n",
    "sorted(result.items(),key=operator.itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remplacer cette boucle en utilisant `map`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 73863), ('of', 39701), ('to', 31788), ('and', 28780), ('a', 28284)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "mapped_values = map(wordcount_map,filenames)\n",
    "\n",
    "result = wordcount_reduce(mapped_values)\n",
    "sorted(result.items(),key=operator.itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version parallèle\n",
    "\n",
    "- Paralléliser l'étape utilisant `wordcount_map` sur 4 processus avec concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.7 ms, sys: 28.4 ms, total: 107 ms\n",
      "Wall time: 502 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor(4)\n",
    "\n",
    "mapped_values = list(e.map(wordcount_map,filenames))\n",
    "result = wordcount_reduce(mapped_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 73863), ('of', 39701), ('to', 31788), ('and', 28780), ('a', 28284)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(result.items(),key=operator.itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark\n",
    "\n",
    "- Paralleliser la boucle avec PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.151-1.b12.fc25.x86_64\n"
     ]
    }
   ],
   "source": [
    "%env JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.151-1.b12.fc25.x86_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sc = pyspark.SparkContext('local[4]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33 ms, sys: 20.7 ms, total: 53.8 ms\n",
      "Wall time: 496 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rdd = sc.parallelize(filenames)\n",
    "mapped_values = rdd.map(wordcount_map).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = wordcount_reduce(mapped_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 73863), ('of', 39701), ('to', 31788), ('and', 28780), ('a', 28284)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(result.items(),key=operator.itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask.bag\n",
    "\n",
    "- Paralléliser la boucle avec Dask.bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "\n",
    "bag = db.from_sequence(filenames)\n",
    "mapped_values = bag.map(wordcount_map).compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 73863), ('of', 39701), ('to', 31788), ('and', 28780), ('a', 28284)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = wordcount_reduce(mapped_values)\n",
    "sorted(result.items(),key=operator.itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask.delayed\n",
    "\n",
    "- Paralléliser la boucle avec Dask.delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 64 ms, sys: 170 ms, total: 234 ms\n",
      "Wall time: 772 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from dask import delayed, compute\n",
    "import dask.multiprocessing\n",
    "\n",
    "delayed_values = [delayed(wordcount_map)(f) for f in filenames]\n",
    "\n",
    "mapped_values = compute(*delayed_values, get=dask.multiprocessing.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 73863), ('of', 39701), ('to', 31788), ('and', 28780), ('a', 28284)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = wordcount_reduce(mapped_values)\n",
    "sorted(result.items(),key=operator.itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: \n",
    " - Donner la liste des mots communs au 4 livres commencant par `q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quite\n",
      "question\n",
      "questioned\n",
      "quarrel\n",
      "quiet\n",
      "quarry\n",
      "queen\n",
      "quickly\n",
      "questioning\n",
      "quarter\n",
      "quarters\n",
      "questions\n",
      "quantity\n",
      "quietly\n",
      "quick\n",
      "quote\n"
     ]
    }
   ],
   "source": [
    "for w in list(set.intersection(*(set(d.keys()) for d in mapped_values))):\n",
    "    if w.startswith('q'):\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
