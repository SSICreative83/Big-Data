{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PySpark and Hadoop\n",
    "\n",
    "In this notebook we look at real data while using our small hadoop cluster. For programming we will use parallel Spark dataframes with real data.\n",
    "\n",
    "We look at [the New York City Taxi Cab dataset](http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml). This includes every ride made in the city of New York in the year 2016.\n",
    "\n",
    "On [this website](http://chriswhong.github.io/nyctaxi/) you can see the data for one random NYC yellow taxi on a single day.\n",
    "\n",
    "On [this post](http://toddwschneider.com/posts/analyzing-1-1-billion-nyc-taxi-and-uber-trips-with-a-vengeance/), you can see an analysis of this dataset. Postgres and R scripts are available on [GitHub](https://github.com/toddwschneider/nyc-taxi-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading the data\n",
    "\n",
    "Normally we would read and load this data into memory as a Pandas dataframe.  However in this case that would be unwise because this data is too large to fit in RAM.\n",
    "\n",
    "The data can stay in the hdfs filesystem but for performance reason we can't use the csv format. The file is large (32Go) and text formatted. Data Access is very slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parquet format\n",
    "\n",
    "[Parquet format](https://github.com/apache/parquet-format) is a common binary data store, used particularly in the Hadoop/big-data sphere. It provides several advantages relevant to big-data processing:\n",
    "\n",
    "- columnar storage, only read the data of interest\n",
    "- efficient binary packing\n",
    "- choice of compression algorithms and encoding\n",
    "- split data into files, allowing for parallel processing\n",
    "- range of logical types\n",
    "- statistics stored in metadata allow for skipping unneeded chunks\n",
    "- data partitioning using the directory structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To convert the csv file to parquet we can use Dask or Spark. Here the code using Spark.\n",
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local[16]') \\\n",
    "        .config('spark.hadoop.parquet.enable.summary-metadata', 'true') \\\n",
    "        .getOrCreate()\n",
    "df = spark.read.csv(\n",
    "    \"hdfs://localhost:54310/user/pnavaro/2016_Yellow_Taxi_Trip_Data.csv\", \n",
    "                    header=\"true\",inferSchema=\"true\")\n",
    "df.write.parquet('hdfs://localhost:54310/user/pnavaro/nyc-taxi/2016.parquet')\n",
    "spark.stop()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## hdfs3\n",
    "\n",
    "[hdfs3](http://hdfs3.readthedocs.io/en/latest/) is an alternative native C/C++ HDFS client that interacts with HDFS without the JVM, exposing first class support to non-JVM languages like Python.\n",
    "\n",
    "This library, hdfs3, is a lightweight Python wrapper around the C/C++ libhdfs3 library. It provides both direct access to libhdfs3 from Python as well as a typical Pythonic interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from hdfs3 import HDFileSystem\n",
    "hdfs = HDFileSystem(host='localhost', port=54310)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from lorem import paragraph\n",
    "with hdfs.open('/user/pnavaro/samples.txt','wb') as f:\n",
    "    f.write(paragraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/user/pnavaro/1990.csv',\n",
       " '/user/pnavaro/1991.csv',\n",
       " '/user/pnavaro/1992.csv',\n",
       " '/user/pnavaro/1993.csv',\n",
       " '/user/pnavaro/1994.csv',\n",
       " '/user/pnavaro/1995.csv',\n",
       " '/user/pnavaro/1996.csv',\n",
       " '/user/pnavaro/1997.csv',\n",
       " '/user/pnavaro/1998.csv',\n",
       " '/user/pnavaro/1999.csv',\n",
       " '/user/pnavaro/2016_Yellow_Taxi_Trip_Data.csv',\n",
       " '/user/pnavaro/copied-file.txt',\n",
       " '/user/pnavaro/nyc-taxi',\n",
       " '/user/pnavaro/nycflights.parquet',\n",
       " '/user/pnavaro/remote-file.txt',\n",
       " '/user/pnavaro/samples.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdfs.ls('/user/pnavaro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from lorem import text\n",
    "with open('local-file.txt','w') as f:\n",
    "    f.write(text())\n",
    "hdfs.put('local-file.txt', '/user/pnavaro/remote-file.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/user/pnavaro/1990.csv',\n",
       " '/user/pnavaro/1991.csv',\n",
       " '/user/pnavaro/1992.csv',\n",
       " '/user/pnavaro/1993.csv',\n",
       " '/user/pnavaro/1994.csv',\n",
       " '/user/pnavaro/1995.csv',\n",
       " '/user/pnavaro/1996.csv',\n",
       " '/user/pnavaro/1997.csv',\n",
       " '/user/pnavaro/1998.csv',\n",
       " '/user/pnavaro/1999.csv',\n",
       " '/user/pnavaro/2016_Yellow_Taxi_Trip_Data.csv',\n",
       " '/user/pnavaro/copied-file.txt',\n",
       " '/user/pnavaro/nyc-taxi',\n",
       " '/user/pnavaro/nycflights.parquet',\n",
       " '/user/pnavaro/remote-file.txt',\n",
       " '/user/pnavaro/samples.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdfs.ls('/user/pnavaro/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdfs.mv('/user/pnavaro/remote-file.txt', '/user/pnavaro/copied-file.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hdfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1a0c562c7a9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/user/pnavaro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hdfs' is not defined"
     ]
    }
   ],
   "source": [
    "hdfs.ls('/user/pnavaro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "We want to implement the WordCount application already coded in notebook 01.MapReduce. \n",
    "This time, files are 1000 times bigger and stored in hadoop file system.\n",
    "\n",
    "### Prepare data and put it on hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from lorem import text\n",
    "with open('sample.txt','w') as f:\n",
    "    for i in range(2250):\n",
    "        f.write(text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cp_file.sh\n"
     ]
    }
   ],
   "source": [
    "%%file cp_file.sh\n",
    "# Makes n number of copies of sample.txt\n",
    "mkdir -p data/latin\n",
    "INPUT=sample.txt\n",
    "for num in $(seq 1 1000)\n",
    "do\n",
    "    bn=$(basename $INPUT .txt)\n",
    "    cp $INPUT data/latin/$bn$num.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!chmod +x cp_file.sh; ./cp_file.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,0G\tdata/latin/\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh data/latin/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Put the sample txt files on hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Get filenames and files size\n",
    "- Change the functions below by using hdfs3 to get filenames and size on HDFS.\n",
    "- Take a look at the [API](http://hdfs3.readthedocs.io/en/latest/api.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample1.txt',\n",
       " 'sample10.txt',\n",
       " 'sample100.txt',\n",
       " 'sample1000.txt',\n",
       " 'sample101.txt',\n",
       " 'sample102.txt',\n",
       " 'sample103.txt',\n",
       " 'sample104.txt',\n",
       " 'sample105.txt',\n",
       " 'sample106.txt',\n",
       " 'sample107.txt',\n",
       " 'sample108.txt',\n",
       " 'sample109.txt',\n",
       " 'sample11.txt',\n",
       " 'sample110.txt',\n",
       " 'sample111.txt',\n",
       " 'sample112.txt',\n",
       " 'sample113.txt',\n",
       " 'sample114.txt',\n",
       " 'sample115.txt',\n",
       " 'sample116.txt',\n",
       " 'sample117.txt',\n",
       " 'sample118.txt',\n",
       " 'sample119.txt',\n",
       " 'sample12.txt',\n",
       " 'sample120.txt',\n",
       " 'sample121.txt',\n",
       " 'sample122.txt',\n",
       " 'sample123.txt',\n",
       " 'sample124.txt',\n",
       " 'sample125.txt',\n",
       " 'sample126.txt',\n",
       " 'sample127.txt',\n",
       " 'sample128.txt',\n",
       " 'sample129.txt',\n",
       " 'sample13.txt',\n",
       " 'sample130.txt',\n",
       " 'sample131.txt',\n",
       " 'sample132.txt',\n",
       " 'sample133.txt',\n",
       " 'sample134.txt',\n",
       " 'sample135.txt',\n",
       " 'sample136.txt',\n",
       " 'sample137.txt',\n",
       " 'sample138.txt',\n",
       " 'sample139.txt',\n",
       " 'sample14.txt',\n",
       " 'sample140.txt',\n",
       " 'sample141.txt',\n",
       " 'sample142.txt',\n",
       " 'sample143.txt',\n",
       " 'sample144.txt',\n",
       " 'sample145.txt',\n",
       " 'sample146.txt',\n",
       " 'sample147.txt',\n",
       " 'sample148.txt',\n",
       " 'sample149.txt',\n",
       " 'sample15.txt',\n",
       " 'sample150.txt',\n",
       " 'sample151.txt',\n",
       " 'sample152.txt',\n",
       " 'sample153.txt',\n",
       " 'sample154.txt',\n",
       " 'sample155.txt',\n",
       " 'sample156.txt',\n",
       " 'sample157.txt',\n",
       " 'sample158.txt',\n",
       " 'sample159.txt',\n",
       " 'sample16.txt',\n",
       " 'sample160.txt',\n",
       " 'sample161.txt',\n",
       " 'sample162.txt',\n",
       " 'sample163.txt',\n",
       " 'sample164.txt',\n",
       " 'sample165.txt',\n",
       " 'sample166.txt',\n",
       " 'sample167.txt',\n",
       " 'sample168.txt',\n",
       " 'sample169.txt',\n",
       " 'sample17.txt',\n",
       " 'sample170.txt',\n",
       " 'sample171.txt',\n",
       " 'sample172.txt',\n",
       " 'sample173.txt',\n",
       " 'sample174.txt',\n",
       " 'sample175.txt',\n",
       " 'sample176.txt',\n",
       " 'sample177.txt',\n",
       " 'sample178.txt',\n",
       " 'sample179.txt',\n",
       " 'sample18.txt',\n",
       " 'sample180.txt',\n",
       " 'sample181.txt',\n",
       " 'sample182.txt',\n",
       " 'sample183.txt',\n",
       " 'sample184.txt',\n",
       " 'sample185.txt',\n",
       " 'sample186.txt',\n",
       " 'sample187.txt',\n",
       " 'sample188.txt',\n",
       " 'sample189.txt',\n",
       " 'sample19.txt',\n",
       " 'sample190.txt',\n",
       " 'sample191.txt',\n",
       " 'sample192.txt',\n",
       " 'sample193.txt',\n",
       " 'sample194.txt',\n",
       " 'sample195.txt',\n",
       " 'sample196.txt',\n",
       " 'sample197.txt',\n",
       " 'sample198.txt',\n",
       " 'sample199.txt',\n",
       " 'sample2.txt',\n",
       " 'sample20.txt',\n",
       " 'sample200.txt',\n",
       " 'sample201.txt',\n",
       " 'sample202.txt',\n",
       " 'sample203.txt',\n",
       " 'sample204.txt',\n",
       " 'sample205.txt',\n",
       " 'sample206.txt',\n",
       " 'sample207.txt',\n",
       " 'sample208.txt',\n",
       " 'sample209.txt',\n",
       " 'sample21.txt',\n",
       " 'sample210.txt',\n",
       " 'sample211.txt',\n",
       " 'sample212.txt',\n",
       " 'sample213.txt',\n",
       " 'sample214.txt',\n",
       " 'sample215.txt',\n",
       " 'sample216.txt',\n",
       " 'sample217.txt',\n",
       " 'sample218.txt',\n",
       " 'sample219.txt',\n",
       " 'sample22.txt',\n",
       " 'sample220.txt',\n",
       " 'sample221.txt',\n",
       " 'sample222.txt',\n",
       " 'sample223.txt',\n",
       " 'sample224.txt',\n",
       " 'sample225.txt',\n",
       " 'sample226.txt',\n",
       " 'sample227.txt',\n",
       " 'sample228.txt',\n",
       " 'sample229.txt',\n",
       " 'sample23.txt',\n",
       " 'sample230.txt',\n",
       " 'sample231.txt',\n",
       " 'sample232.txt',\n",
       " 'sample233.txt',\n",
       " 'sample234.txt',\n",
       " 'sample235.txt',\n",
       " 'sample236.txt',\n",
       " 'sample237.txt',\n",
       " 'sample238.txt',\n",
       " 'sample239.txt',\n",
       " 'sample24.txt',\n",
       " 'sample240.txt',\n",
       " 'sample241.txt',\n",
       " 'sample242.txt',\n",
       " 'sample243.txt',\n",
       " 'sample244.txt',\n",
       " 'sample245.txt',\n",
       " 'sample246.txt',\n",
       " 'sample247.txt',\n",
       " 'sample248.txt',\n",
       " 'sample249.txt',\n",
       " 'sample25.txt',\n",
       " 'sample250.txt',\n",
       " 'sample251.txt',\n",
       " 'sample252.txt',\n",
       " 'sample253.txt',\n",
       " 'sample254.txt',\n",
       " 'sample255.txt',\n",
       " 'sample256.txt',\n",
       " 'sample257.txt',\n",
       " 'sample258.txt',\n",
       " 'sample259.txt',\n",
       " 'sample26.txt',\n",
       " 'sample260.txt',\n",
       " 'sample261.txt',\n",
       " 'sample262.txt',\n",
       " 'sample263.txt',\n",
       " 'sample264.txt',\n",
       " 'sample265.txt',\n",
       " 'sample266.txt',\n",
       " 'sample267.txt',\n",
       " 'sample268.txt',\n",
       " 'sample269.txt',\n",
       " 'sample27.txt',\n",
       " 'sample270.txt',\n",
       " 'sample271.txt',\n",
       " 'sample272.txt',\n",
       " 'sample273.txt',\n",
       " 'sample274.txt',\n",
       " 'sample275.txt',\n",
       " 'sample276.txt',\n",
       " 'sample277.txt',\n",
       " 'sample278.txt',\n",
       " 'sample279.txt',\n",
       " 'sample28.txt',\n",
       " 'sample280.txt',\n",
       " 'sample281.txt',\n",
       " 'sample282.txt',\n",
       " 'sample283.txt',\n",
       " 'sample284.txt',\n",
       " 'sample285.txt',\n",
       " 'sample286.txt',\n",
       " 'sample287.txt',\n",
       " 'sample288.txt',\n",
       " 'sample289.txt',\n",
       " 'sample29.txt',\n",
       " 'sample290.txt',\n",
       " 'sample291.txt',\n",
       " 'sample292.txt',\n",
       " 'sample293.txt',\n",
       " 'sample294.txt',\n",
       " 'sample295.txt',\n",
       " 'sample296.txt',\n",
       " 'sample297.txt',\n",
       " 'sample298.txt',\n",
       " 'sample299.txt',\n",
       " 'sample3.txt',\n",
       " 'sample30.txt',\n",
       " 'sample300.txt',\n",
       " 'sample301.txt',\n",
       " 'sample302.txt',\n",
       " 'sample303.txt',\n",
       " 'sample304.txt',\n",
       " 'sample305.txt',\n",
       " 'sample306.txt',\n",
       " 'sample307.txt',\n",
       " 'sample308.txt',\n",
       " 'sample309.txt',\n",
       " 'sample31.txt',\n",
       " 'sample310.txt',\n",
       " 'sample311.txt',\n",
       " 'sample312.txt',\n",
       " 'sample313.txt',\n",
       " 'sample314.txt',\n",
       " 'sample315.txt',\n",
       " 'sample316.txt',\n",
       " 'sample317.txt',\n",
       " 'sample318.txt',\n",
       " 'sample319.txt',\n",
       " 'sample32.txt',\n",
       " 'sample320.txt',\n",
       " 'sample321.txt',\n",
       " 'sample322.txt',\n",
       " 'sample323.txt',\n",
       " 'sample324.txt',\n",
       " 'sample325.txt',\n",
       " 'sample326.txt',\n",
       " 'sample327.txt',\n",
       " 'sample328.txt',\n",
       " 'sample329.txt',\n",
       " 'sample33.txt',\n",
       " 'sample330.txt',\n",
       " 'sample331.txt',\n",
       " 'sample332.txt',\n",
       " 'sample333.txt',\n",
       " 'sample334.txt',\n",
       " 'sample335.txt',\n",
       " 'sample336.txt',\n",
       " 'sample337.txt',\n",
       " 'sample338.txt',\n",
       " 'sample339.txt',\n",
       " 'sample34.txt',\n",
       " 'sample340.txt',\n",
       " 'sample341.txt',\n",
       " 'sample342.txt',\n",
       " 'sample343.txt',\n",
       " 'sample344.txt',\n",
       " 'sample345.txt',\n",
       " 'sample346.txt',\n",
       " 'sample347.txt',\n",
       " 'sample348.txt',\n",
       " 'sample349.txt',\n",
       " 'sample35.txt',\n",
       " 'sample350.txt',\n",
       " 'sample351.txt',\n",
       " 'sample352.txt',\n",
       " 'sample353.txt',\n",
       " 'sample354.txt',\n",
       " 'sample355.txt',\n",
       " 'sample356.txt',\n",
       " 'sample357.txt',\n",
       " 'sample358.txt',\n",
       " 'sample359.txt',\n",
       " 'sample36.txt',\n",
       " 'sample360.txt',\n",
       " 'sample361.txt',\n",
       " 'sample362.txt',\n",
       " 'sample363.txt',\n",
       " 'sample364.txt',\n",
       " 'sample365.txt',\n",
       " 'sample366.txt',\n",
       " 'sample367.txt',\n",
       " 'sample368.txt',\n",
       " 'sample369.txt',\n",
       " 'sample37.txt',\n",
       " 'sample370.txt',\n",
       " 'sample371.txt',\n",
       " 'sample372.txt',\n",
       " 'sample373.txt',\n",
       " 'sample374.txt',\n",
       " 'sample375.txt',\n",
       " 'sample376.txt',\n",
       " 'sample377.txt',\n",
       " 'sample378.txt',\n",
       " 'sample379.txt',\n",
       " 'sample38.txt',\n",
       " 'sample380.txt',\n",
       " 'sample381.txt',\n",
       " 'sample382.txt',\n",
       " 'sample383.txt',\n",
       " 'sample384.txt',\n",
       " 'sample385.txt',\n",
       " 'sample386.txt',\n",
       " 'sample387.txt',\n",
       " 'sample388.txt',\n",
       " 'sample389.txt',\n",
       " 'sample39.txt',\n",
       " 'sample390.txt',\n",
       " 'sample391.txt',\n",
       " 'sample392.txt',\n",
       " 'sample393.txt',\n",
       " 'sample394.txt',\n",
       " 'sample395.txt',\n",
       " 'sample396.txt',\n",
       " 'sample397.txt',\n",
       " 'sample398.txt',\n",
       " 'sample399.txt',\n",
       " 'sample4.txt',\n",
       " 'sample40.txt',\n",
       " 'sample400.txt',\n",
       " 'sample401.txt',\n",
       " 'sample402.txt',\n",
       " 'sample403.txt',\n",
       " 'sample404.txt',\n",
       " 'sample405.txt',\n",
       " 'sample406.txt',\n",
       " 'sample407.txt',\n",
       " 'sample408.txt',\n",
       " 'sample409.txt',\n",
       " 'sample41.txt',\n",
       " 'sample410.txt',\n",
       " 'sample411.txt',\n",
       " 'sample412.txt',\n",
       " 'sample413.txt',\n",
       " 'sample414.txt',\n",
       " 'sample415.txt',\n",
       " 'sample416.txt',\n",
       " 'sample417.txt',\n",
       " 'sample418.txt',\n",
       " 'sample419.txt',\n",
       " 'sample42.txt',\n",
       " 'sample420.txt',\n",
       " 'sample421.txt',\n",
       " 'sample422.txt',\n",
       " 'sample423.txt',\n",
       " 'sample424.txt',\n",
       " 'sample425.txt',\n",
       " 'sample426.txt',\n",
       " 'sample427.txt',\n",
       " 'sample428.txt',\n",
       " 'sample429.txt',\n",
       " 'sample43.txt',\n",
       " 'sample430.txt',\n",
       " 'sample431.txt',\n",
       " 'sample432.txt',\n",
       " 'sample433.txt',\n",
       " 'sample434.txt',\n",
       " 'sample435.txt',\n",
       " 'sample436.txt',\n",
       " 'sample437.txt',\n",
       " 'sample438.txt',\n",
       " 'sample439.txt',\n",
       " 'sample44.txt',\n",
       " 'sample440.txt',\n",
       " 'sample441.txt',\n",
       " 'sample442.txt',\n",
       " 'sample443.txt',\n",
       " 'sample444.txt',\n",
       " 'sample445.txt',\n",
       " 'sample446.txt',\n",
       " 'sample447.txt',\n",
       " 'sample448.txt',\n",
       " 'sample449.txt',\n",
       " 'sample45.txt',\n",
       " 'sample450.txt',\n",
       " 'sample451.txt',\n",
       " 'sample452.txt',\n",
       " 'sample453.txt',\n",
       " 'sample454.txt',\n",
       " 'sample455.txt',\n",
       " 'sample456.txt',\n",
       " 'sample457.txt',\n",
       " 'sample458.txt',\n",
       " 'sample459.txt',\n",
       " 'sample46.txt',\n",
       " 'sample460.txt',\n",
       " 'sample461.txt',\n",
       " 'sample462.txt',\n",
       " 'sample463.txt',\n",
       " 'sample464.txt',\n",
       " 'sample465.txt',\n",
       " 'sample466.txt',\n",
       " 'sample467.txt',\n",
       " 'sample468.txt',\n",
       " 'sample469.txt',\n",
       " 'sample47.txt',\n",
       " 'sample470.txt',\n",
       " 'sample471.txt',\n",
       " 'sample472.txt',\n",
       " 'sample473.txt',\n",
       " 'sample474.txt',\n",
       " 'sample475.txt',\n",
       " 'sample476.txt',\n",
       " 'sample477.txt',\n",
       " 'sample478.txt',\n",
       " 'sample479.txt',\n",
       " 'sample48.txt',\n",
       " 'sample480.txt',\n",
       " 'sample481.txt',\n",
       " 'sample482.txt',\n",
       " 'sample483.txt',\n",
       " 'sample484.txt',\n",
       " 'sample485.txt',\n",
       " 'sample486.txt',\n",
       " 'sample487.txt',\n",
       " 'sample488.txt',\n",
       " 'sample489.txt',\n",
       " 'sample49.txt',\n",
       " 'sample490.txt',\n",
       " 'sample491.txt',\n",
       " 'sample492.txt',\n",
       " 'sample493.txt',\n",
       " 'sample494.txt',\n",
       " 'sample495.txt',\n",
       " 'sample496.txt',\n",
       " 'sample497.txt',\n",
       " 'sample498.txt',\n",
       " 'sample499.txt',\n",
       " 'sample5.txt',\n",
       " 'sample50.txt',\n",
       " 'sample500.txt',\n",
       " 'sample501.txt',\n",
       " 'sample502.txt',\n",
       " 'sample503.txt',\n",
       " 'sample504.txt',\n",
       " 'sample505.txt',\n",
       " 'sample506.txt',\n",
       " 'sample507.txt',\n",
       " 'sample508.txt',\n",
       " 'sample509.txt',\n",
       " 'sample51.txt',\n",
       " 'sample510.txt',\n",
       " 'sample511.txt',\n",
       " 'sample512.txt',\n",
       " 'sample513.txt',\n",
       " 'sample514.txt',\n",
       " 'sample515.txt',\n",
       " 'sample516.txt',\n",
       " 'sample517.txt',\n",
       " 'sample518.txt',\n",
       " 'sample519.txt',\n",
       " 'sample52.txt',\n",
       " 'sample520.txt',\n",
       " 'sample521.txt',\n",
       " 'sample522.txt',\n",
       " 'sample523.txt',\n",
       " 'sample524.txt',\n",
       " 'sample525.txt',\n",
       " 'sample526.txt',\n",
       " 'sample527.txt',\n",
       " 'sample528.txt',\n",
       " 'sample529.txt',\n",
       " 'sample53.txt',\n",
       " 'sample530.txt',\n",
       " 'sample531.txt',\n",
       " 'sample532.txt',\n",
       " 'sample533.txt',\n",
       " 'sample534.txt',\n",
       " 'sample535.txt',\n",
       " 'sample536.txt',\n",
       " 'sample537.txt',\n",
       " 'sample538.txt',\n",
       " 'sample539.txt',\n",
       " 'sample54.txt',\n",
       " 'sample540.txt',\n",
       " 'sample541.txt',\n",
       " 'sample542.txt',\n",
       " 'sample543.txt',\n",
       " 'sample544.txt',\n",
       " 'sample545.txt',\n",
       " 'sample546.txt',\n",
       " 'sample547.txt',\n",
       " 'sample548.txt',\n",
       " 'sample549.txt',\n",
       " 'sample55.txt',\n",
       " 'sample550.txt',\n",
       " 'sample551.txt',\n",
       " 'sample552.txt',\n",
       " 'sample553.txt',\n",
       " 'sample554.txt',\n",
       " 'sample555.txt',\n",
       " 'sample556.txt',\n",
       " 'sample557.txt',\n",
       " 'sample558.txt',\n",
       " 'sample559.txt',\n",
       " 'sample56.txt',\n",
       " 'sample560.txt',\n",
       " 'sample561.txt',\n",
       " 'sample562.txt',\n",
       " 'sample563.txt',\n",
       " 'sample564.txt',\n",
       " 'sample565.txt',\n",
       " 'sample566.txt',\n",
       " 'sample567.txt',\n",
       " 'sample568.txt',\n",
       " 'sample569.txt',\n",
       " 'sample57.txt',\n",
       " 'sample570.txt',\n",
       " 'sample571.txt',\n",
       " 'sample572.txt',\n",
       " 'sample573.txt',\n",
       " 'sample574.txt',\n",
       " 'sample575.txt',\n",
       " 'sample576.txt',\n",
       " 'sample577.txt',\n",
       " 'sample578.txt',\n",
       " 'sample579.txt',\n",
       " 'sample58.txt',\n",
       " 'sample580.txt',\n",
       " 'sample581.txt',\n",
       " 'sample582.txt',\n",
       " 'sample583.txt',\n",
       " 'sample584.txt',\n",
       " 'sample585.txt',\n",
       " 'sample586.txt',\n",
       " 'sample587.txt',\n",
       " 'sample588.txt',\n",
       " 'sample589.txt',\n",
       " 'sample59.txt',\n",
       " 'sample590.txt',\n",
       " 'sample591.txt',\n",
       " 'sample592.txt',\n",
       " 'sample593.txt',\n",
       " 'sample594.txt',\n",
       " 'sample595.txt',\n",
       " 'sample596.txt',\n",
       " 'sample597.txt',\n",
       " 'sample598.txt',\n",
       " 'sample599.txt',\n",
       " 'sample6.txt',\n",
       " 'sample60.txt',\n",
       " 'sample600.txt',\n",
       " 'sample601.txt',\n",
       " 'sample602.txt',\n",
       " 'sample603.txt',\n",
       " 'sample604.txt',\n",
       " 'sample605.txt',\n",
       " 'sample606.txt',\n",
       " 'sample607.txt',\n",
       " 'sample608.txt',\n",
       " 'sample609.txt',\n",
       " 'sample61.txt',\n",
       " 'sample610.txt',\n",
       " 'sample611.txt',\n",
       " 'sample612.txt',\n",
       " 'sample613.txt',\n",
       " 'sample614.txt',\n",
       " 'sample615.txt',\n",
       " 'sample616.txt',\n",
       " 'sample617.txt',\n",
       " 'sample618.txt',\n",
       " 'sample619.txt',\n",
       " 'sample62.txt',\n",
       " 'sample620.txt',\n",
       " 'sample621.txt',\n",
       " 'sample622.txt',\n",
       " 'sample623.txt',\n",
       " 'sample624.txt',\n",
       " 'sample625.txt',\n",
       " 'sample626.txt',\n",
       " 'sample627.txt',\n",
       " 'sample628.txt',\n",
       " 'sample629.txt',\n",
       " 'sample63.txt',\n",
       " 'sample630.txt',\n",
       " 'sample631.txt',\n",
       " 'sample632.txt',\n",
       " 'sample633.txt',\n",
       " 'sample634.txt',\n",
       " 'sample635.txt',\n",
       " 'sample636.txt',\n",
       " 'sample637.txt',\n",
       " 'sample638.txt',\n",
       " 'sample639.txt',\n",
       " 'sample64.txt',\n",
       " 'sample640.txt',\n",
       " 'sample641.txt',\n",
       " 'sample642.txt',\n",
       " 'sample643.txt',\n",
       " 'sample644.txt',\n",
       " 'sample645.txt',\n",
       " 'sample646.txt',\n",
       " 'sample647.txt',\n",
       " 'sample648.txt',\n",
       " 'sample649.txt',\n",
       " 'sample65.txt',\n",
       " 'sample650.txt',\n",
       " 'sample651.txt',\n",
       " 'sample652.txt',\n",
       " 'sample653.txt',\n",
       " 'sample654.txt',\n",
       " 'sample655.txt',\n",
       " 'sample656.txt',\n",
       " 'sample657.txt',\n",
       " 'sample658.txt',\n",
       " 'sample659.txt',\n",
       " 'sample66.txt',\n",
       " 'sample660.txt',\n",
       " 'sample661.txt',\n",
       " 'sample662.txt',\n",
       " 'sample663.txt',\n",
       " 'sample664.txt',\n",
       " 'sample665.txt',\n",
       " 'sample666.txt',\n",
       " 'sample667.txt',\n",
       " 'sample668.txt',\n",
       " 'sample669.txt',\n",
       " 'sample67.txt',\n",
       " 'sample670.txt',\n",
       " 'sample671.txt',\n",
       " 'sample672.txt',\n",
       " 'sample673.txt',\n",
       " 'sample674.txt',\n",
       " 'sample675.txt',\n",
       " 'sample676.txt',\n",
       " 'sample677.txt',\n",
       " 'sample678.txt',\n",
       " 'sample679.txt',\n",
       " 'sample68.txt',\n",
       " 'sample680.txt',\n",
       " 'sample681.txt',\n",
       " 'sample682.txt',\n",
       " 'sample683.txt',\n",
       " 'sample684.txt',\n",
       " 'sample685.txt',\n",
       " 'sample686.txt',\n",
       " 'sample687.txt',\n",
       " 'sample688.txt',\n",
       " 'sample689.txt',\n",
       " 'sample69.txt',\n",
       " 'sample690.txt',\n",
       " 'sample691.txt',\n",
       " 'sample692.txt',\n",
       " 'sample693.txt',\n",
       " 'sample694.txt',\n",
       " 'sample695.txt',\n",
       " 'sample696.txt',\n",
       " 'sample697.txt',\n",
       " 'sample698.txt',\n",
       " 'sample699.txt',\n",
       " 'sample7.txt',\n",
       " 'sample70.txt',\n",
       " 'sample700.txt',\n",
       " 'sample701.txt',\n",
       " 'sample702.txt',\n",
       " 'sample703.txt',\n",
       " 'sample704.txt',\n",
       " 'sample705.txt',\n",
       " 'sample706.txt',\n",
       " 'sample707.txt',\n",
       " 'sample708.txt',\n",
       " 'sample709.txt',\n",
       " 'sample71.txt',\n",
       " 'sample710.txt',\n",
       " 'sample711.txt',\n",
       " 'sample712.txt',\n",
       " 'sample713.txt',\n",
       " 'sample714.txt',\n",
       " 'sample715.txt',\n",
       " 'sample716.txt',\n",
       " 'sample717.txt',\n",
       " 'sample718.txt',\n",
       " 'sample719.txt',\n",
       " 'sample72.txt',\n",
       " 'sample720.txt',\n",
       " 'sample721.txt',\n",
       " 'sample722.txt',\n",
       " 'sample723.txt',\n",
       " 'sample724.txt',\n",
       " 'sample725.txt',\n",
       " 'sample726.txt',\n",
       " 'sample727.txt',\n",
       " 'sample728.txt',\n",
       " 'sample729.txt',\n",
       " 'sample73.txt',\n",
       " 'sample730.txt',\n",
       " 'sample731.txt',\n",
       " 'sample732.txt',\n",
       " 'sample733.txt',\n",
       " 'sample734.txt',\n",
       " 'sample735.txt',\n",
       " 'sample736.txt',\n",
       " 'sample737.txt',\n",
       " 'sample738.txt',\n",
       " 'sample739.txt',\n",
       " 'sample74.txt',\n",
       " 'sample740.txt',\n",
       " 'sample741.txt',\n",
       " 'sample742.txt',\n",
       " 'sample743.txt',\n",
       " 'sample744.txt',\n",
       " 'sample745.txt',\n",
       " 'sample746.txt',\n",
       " 'sample747.txt',\n",
       " 'sample748.txt',\n",
       " 'sample749.txt',\n",
       " 'sample75.txt',\n",
       " 'sample750.txt',\n",
       " 'sample751.txt',\n",
       " 'sample752.txt',\n",
       " 'sample753.txt',\n",
       " 'sample754.txt',\n",
       " 'sample755.txt',\n",
       " 'sample756.txt',\n",
       " 'sample757.txt',\n",
       " 'sample758.txt',\n",
       " 'sample759.txt',\n",
       " 'sample76.txt',\n",
       " 'sample760.txt',\n",
       " 'sample761.txt',\n",
       " 'sample762.txt',\n",
       " 'sample763.txt',\n",
       " 'sample764.txt',\n",
       " 'sample765.txt',\n",
       " 'sample766.txt',\n",
       " 'sample767.txt',\n",
       " 'sample768.txt',\n",
       " 'sample769.txt',\n",
       " 'sample77.txt',\n",
       " 'sample770.txt',\n",
       " 'sample771.txt',\n",
       " 'sample772.txt',\n",
       " 'sample773.txt',\n",
       " 'sample774.txt',\n",
       " 'sample775.txt',\n",
       " 'sample776.txt',\n",
       " 'sample777.txt',\n",
       " 'sample778.txt',\n",
       " 'sample779.txt',\n",
       " 'sample78.txt',\n",
       " 'sample780.txt',\n",
       " 'sample781.txt',\n",
       " 'sample782.txt',\n",
       " 'sample783.txt',\n",
       " 'sample784.txt',\n",
       " 'sample785.txt',\n",
       " 'sample786.txt',\n",
       " 'sample787.txt',\n",
       " 'sample788.txt',\n",
       " 'sample789.txt',\n",
       " 'sample79.txt',\n",
       " 'sample790.txt',\n",
       " 'sample791.txt',\n",
       " 'sample792.txt',\n",
       " 'sample793.txt',\n",
       " 'sample794.txt',\n",
       " 'sample795.txt',\n",
       " 'sample796.txt',\n",
       " 'sample797.txt',\n",
       " 'sample798.txt',\n",
       " 'sample799.txt',\n",
       " 'sample8.txt',\n",
       " 'sample80.txt',\n",
       " 'sample800.txt',\n",
       " 'sample801.txt',\n",
       " 'sample802.txt',\n",
       " 'sample803.txt',\n",
       " 'sample804.txt',\n",
       " 'sample805.txt',\n",
       " 'sample806.txt',\n",
       " 'sample807.txt',\n",
       " 'sample808.txt',\n",
       " 'sample809.txt',\n",
       " 'sample81.txt',\n",
       " 'sample810.txt',\n",
       " 'sample811.txt',\n",
       " 'sample812.txt',\n",
       " 'sample813.txt',\n",
       " 'sample814.txt',\n",
       " 'sample815.txt',\n",
       " 'sample816.txt',\n",
       " 'sample817.txt',\n",
       " 'sample818.txt',\n",
       " 'sample819.txt',\n",
       " 'sample82.txt',\n",
       " 'sample820.txt',\n",
       " 'sample821.txt',\n",
       " 'sample822.txt',\n",
       " 'sample823.txt',\n",
       " 'sample824.txt',\n",
       " 'sample825.txt',\n",
       " 'sample826.txt',\n",
       " 'sample827.txt',\n",
       " 'sample828.txt',\n",
       " 'sample829.txt',\n",
       " 'sample83.txt',\n",
       " 'sample830.txt',\n",
       " 'sample831.txt',\n",
       " 'sample832.txt',\n",
       " 'sample833.txt',\n",
       " 'sample834.txt',\n",
       " 'sample835.txt',\n",
       " 'sample836.txt',\n",
       " 'sample837.txt',\n",
       " 'sample838.txt',\n",
       " 'sample839.txt',\n",
       " 'sample84.txt',\n",
       " 'sample840.txt',\n",
       " 'sample841.txt',\n",
       " 'sample842.txt',\n",
       " 'sample843.txt',\n",
       " 'sample844.txt',\n",
       " 'sample845.txt',\n",
       " 'sample846.txt',\n",
       " 'sample847.txt',\n",
       " 'sample848.txt',\n",
       " 'sample849.txt',\n",
       " 'sample85.txt',\n",
       " 'sample850.txt',\n",
       " 'sample851.txt',\n",
       " 'sample852.txt',\n",
       " 'sample853.txt',\n",
       " 'sample854.txt',\n",
       " 'sample855.txt',\n",
       " 'sample856.txt',\n",
       " 'sample857.txt',\n",
       " 'sample858.txt',\n",
       " 'sample859.txt',\n",
       " 'sample86.txt',\n",
       " 'sample860.txt',\n",
       " 'sample861.txt',\n",
       " 'sample862.txt',\n",
       " 'sample863.txt',\n",
       " 'sample864.txt',\n",
       " 'sample865.txt',\n",
       " 'sample866.txt',\n",
       " 'sample867.txt',\n",
       " 'sample868.txt',\n",
       " 'sample869.txt',\n",
       " 'sample87.txt',\n",
       " 'sample870.txt',\n",
       " 'sample871.txt',\n",
       " 'sample872.txt',\n",
       " 'sample873.txt',\n",
       " 'sample874.txt',\n",
       " 'sample875.txt',\n",
       " 'sample876.txt',\n",
       " 'sample877.txt',\n",
       " 'sample878.txt',\n",
       " 'sample879.txt',\n",
       " 'sample88.txt',\n",
       " 'sample880.txt',\n",
       " 'sample881.txt',\n",
       " 'sample882.txt',\n",
       " 'sample883.txt',\n",
       " 'sample884.txt',\n",
       " 'sample885.txt',\n",
       " 'sample886.txt',\n",
       " 'sample887.txt',\n",
       " 'sample888.txt',\n",
       " 'sample889.txt',\n",
       " 'sample89.txt',\n",
       " 'sample890.txt',\n",
       " 'sample891.txt',\n",
       " 'sample892.txt',\n",
       " 'sample893.txt',\n",
       " 'sample894.txt',\n",
       " 'sample895.txt',\n",
       " 'sample896.txt',\n",
       " 'sample897.txt',\n",
       " 'sample898.txt',\n",
       " 'sample899.txt',\n",
       " 'sample9.txt',\n",
       " 'sample90.txt',\n",
       " 'sample900.txt',\n",
       " 'sample901.txt',\n",
       " 'sample902.txt',\n",
       " 'sample903.txt',\n",
       " 'sample904.txt',\n",
       " 'sample905.txt',\n",
       " 'sample906.txt',\n",
       " 'sample907.txt',\n",
       " 'sample908.txt',\n",
       " 'sample909.txt',\n",
       " 'sample91.txt',\n",
       " 'sample910.txt',\n",
       " 'sample911.txt',\n",
       " 'sample912.txt',\n",
       " 'sample913.txt',\n",
       " 'sample914.txt',\n",
       " 'sample915.txt',\n",
       " 'sample916.txt',\n",
       " 'sample917.txt',\n",
       " 'sample918.txt',\n",
       " 'sample919.txt',\n",
       " 'sample92.txt',\n",
       " 'sample920.txt',\n",
       " 'sample921.txt',\n",
       " 'sample922.txt',\n",
       " 'sample923.txt',\n",
       " 'sample924.txt',\n",
       " 'sample925.txt',\n",
       " 'sample926.txt',\n",
       " 'sample927.txt',\n",
       " 'sample928.txt',\n",
       " 'sample929.txt',\n",
       " 'sample93.txt',\n",
       " 'sample930.txt',\n",
       " 'sample931.txt',\n",
       " 'sample932.txt',\n",
       " 'sample933.txt',\n",
       " 'sample934.txt',\n",
       " 'sample935.txt',\n",
       " 'sample936.txt',\n",
       " 'sample937.txt',\n",
       " 'sample938.txt',\n",
       " 'sample939.txt',\n",
       " 'sample94.txt',\n",
       " 'sample940.txt',\n",
       " 'sample941.txt',\n",
       " 'sample942.txt',\n",
       " 'sample943.txt',\n",
       " 'sample944.txt',\n",
       " 'sample945.txt',\n",
       " 'sample946.txt',\n",
       " 'sample947.txt',\n",
       " 'sample948.txt',\n",
       " 'sample949.txt',\n",
       " 'sample95.txt',\n",
       " 'sample950.txt',\n",
       " 'sample951.txt',\n",
       " 'sample952.txt',\n",
       " 'sample953.txt',\n",
       " 'sample954.txt',\n",
       " 'sample955.txt',\n",
       " 'sample956.txt',\n",
       " 'sample957.txt',\n",
       " 'sample958.txt',\n",
       " 'sample959.txt',\n",
       " 'sample96.txt',\n",
       " 'sample960.txt',\n",
       " 'sample961.txt',\n",
       " 'sample962.txt',\n",
       " 'sample963.txt',\n",
       " 'sample964.txt',\n",
       " 'sample965.txt',\n",
       " 'sample966.txt',\n",
       " 'sample967.txt',\n",
       " 'sample968.txt',\n",
       " 'sample969.txt',\n",
       " 'sample97.txt',\n",
       " 'sample970.txt',\n",
       " 'sample971.txt',\n",
       " 'sample972.txt',\n",
       " 'sample973.txt',\n",
       " 'sample974.txt',\n",
       " 'sample975.txt',\n",
       " 'sample976.txt',\n",
       " 'sample977.txt',\n",
       " 'sample978.txt',\n",
       " 'sample979.txt',\n",
       " 'sample98.txt',\n",
       " 'sample980.txt',\n",
       " 'sample981.txt',\n",
       " 'sample982.txt',\n",
       " 'sample983.txt',\n",
       " 'sample984.txt',\n",
       " 'sample985.txt',\n",
       " 'sample986.txt',\n",
       " 'sample987.txt',\n",
       " 'sample988.txt',\n",
       " 'sample989.txt',\n",
       " 'sample99.txt',\n",
       " 'sample990.txt',\n",
       " 'sample991.txt',\n",
       " 'sample992.txt',\n",
       " 'sample993.txt',\n",
       " 'sample994.txt',\n",
       " 'sample995.txt',\n",
       " 'sample996.txt',\n",
       " 'sample997.txt',\n",
       " 'sample998.txt',\n",
       " 'sample999.txt']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def get_filenames(root):\n",
    "\t\"\"\"\n",
    "\tReturns complete list of filenames in root directory\n",
    "    \"\"\"\n",
    "\n",
    "\tfiles = []\n",
    "\tfor f in os.listdir(root):\n",
    "\t\tif f.endswith(\".txt\"):\n",
    "\t\t\tfiles.append(f)\n",
    "\t\n",
    "\treturn files\n",
    "\n",
    "root = os.path.join(os.getcwd(),'data','latin')\n",
    "get_filenames(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of files: 2.9646381735801697 GB\n"
     ]
    }
   ],
   "source": [
    "def files_total_size(root):\n",
    "   \"\"\"\n",
    "   Prints sum of filesize of files to be mapreduced\n",
    "   \"\"\"\n",
    "   filesize = 0\n",
    "   for f in os.listdir(root):\n",
    "       if f.endswith(\".txt\"):\n",
    "           filesize += os.path.getsize(os.path.join(root,f))\n",
    "\n",
    "   print(\"Size of files:\", filesize / 1073741824, \"GB\")\n",
    "\n",
    "files_total_size(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[fastparquet](http://fastparquet.readthedocs.io/en/latest/) provides a performant library to read and write Parquet files from Python, without any need for a Python-Java bridge. This will make the Parquet format an ideal storage mechanism for Python-based big data workflows.\n",
    "\n",
    "The tabular nature of Parquet is a good fit for the Pandas data-frame objects, and we exclusively deal with data-frame<->Parquet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Apache Arrow](https://arrow.apache.org/docs/python/)\n",
    "\n",
    "Arrow is a columnar in-memory analytics layer designed to accelerate big data. It houses a set of canonical in-memory representations of flat and hierarchical data along with multiple language-bindings for structure manipulation.\n",
    "\n",
    "https://arrow.apache.org/docs/python/parquet.html\n",
    "\n",
    "The Apache Parquet project provides a standardized open-source columnar storage format for use in data analysis systems. It was created originally for use in Apache Hadoop with systems like Apache Drill, Apache Hive, Apache Impala (incubating), and Apache Spark adopting it as a shared standard for high performance data IO.\n",
    "\n",
    "Apache Arrow is an ideal in-memory transport layer for data that is being read or written with Parquet files. [PyArrow](https://arrow.apache.org/docs/python/) includes Python bindings to read and write Parquet files with pandas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Parquet File: {'name': '/user/pnavaro/nyc-taxi/2016.parquet/_metadata', 'columns': ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'pickup_longitude', 'pickup_latitude', 'RatecodeID', 'store_and_fwd_flag', 'dropoff_longitude', 'dropoff_latitude', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'PULocationID', 'DOLocationID'], 'partitions': [], 'rows': 131165043}>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastparquet as fp\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "hdfs = pa.hdfs.connect('localhost', 54310, 'pnavaro', driver='libhdfs3')\n",
    "\n",
    "pf = fp.ParquetFile('/user/pnavaro/nyc-taxi/2016.parquet', open_with=hdfs.open)\n",
    "pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql import SparkSession\n",
    "#spark = SparkSession.builder.master('spark://schedulers:7077').getOrCreate()\n",
    "#spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['tpep_pickup_datetime', 'passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'payment_type', 'fare_amount', 'tip_amount', 'total_amount']\n",
    "\n",
    "df = (spark.read.parquet('hdfs://localhost:54310/user/pnavaro/nyc-taxi/2016.parquet')\n",
    "           .select(*columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sum the total number of passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sum(passenger_count)=217355302)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.agg({'passenger_count': 'sum'}).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(passenger_count)=1.6571130312517794)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.agg({'passenger_count': 'avg'}).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(passenger_count=1, count(1)=92987719),\n",
       " Row(passenger_count=6, count(1)=4234423),\n",
       " Row(passenger_count=3, count(1)=5456807),\n",
       " Row(passenger_count=5, count(1)=6773026),\n",
       " Row(passenger_count=9, count(1)=261),\n",
       " Row(passenger_count=4, count(1)=2660369),\n",
       " Row(passenger_count=8, count(1)=316),\n",
       " Row(passenger_count=7, count(1)=361),\n",
       " Row(passenger_count=2, count(1)=19038307),\n",
       " Row(passenger_count=0, count(1)=13454)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('passenger_count').agg({'*': 'count'}).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Use the `filter`, `groupBy`, `agg` operations to find out how well New Yorkers tip based on the number of passengers in the cab.\n",
    " 1. Remove rides with zero fare\n",
    " 2. Add a new column tip_fraction that is equal to the ratio of the tip to the fare\n",
    " 3. Group by the passenger_count column and take the mean of the tip_fraction column.\n",
    " \n",
    "You may want to refer to these resources to help you with the Spark DataFrame API\n",
    "- https://spark.apache.org/docs/latest/api/python/pyspark.sql.html\n",
    "- https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf\n",
    "And refer to the Spark UI for feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to remove rows\n",
    "\n",
    "In Spark you can filter rows by a boolean expression like the following:\n",
    "```python\n",
    "df.filter(df.name == 'Alice')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to make new columns\n",
    "\n",
    "In Pandas you can create a new column using Python's setitem syntax like the following:\n",
    "\n",
    "```python\n",
    "df = df.withColumn('z', df.x + df.y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do groupby-aggregations\n",
    "\n",
    "In Pandas you can do a groupby-aggregation by using the `groupby` method, followed by a column name an aggregation method like the following:\n",
    "\n",
    "```python\n",
    "df.groupBy(df.name).agg({'column-name': 'avg'})\n",
    "```\n",
    "\n",
    "When you want to collect the result of your computation, finish with the `.collect()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. How well do New Yorkers tip as a function of the hour of day and the day of the week?\n",
    "2. Investiate the `payment_type` column.  See how well each of the payment types correlate with the `tip_fraction`.  Did you find anything interesting?  Any guesses on what the different payment types might be?  If you're interested you may be able to find more information on the [NYC TLC's website](http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml)\n",
    "3. How quickly can you get the data for a particular day of the year?  How about for a particular hour of that day?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
