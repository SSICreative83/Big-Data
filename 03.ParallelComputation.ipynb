{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Pierre Navaro - [Institut de Recherche Mathématique de Rennes](https://irmar.univ-rennes1.fr) - [CNRS](http://www.cnrs.fr/)\n",
    "\n",
    "https://github.com/pnavaro/big-data/blob/master/03.ParallelComputation.ipynb\n",
    "\n",
    "[Display on nbviewer](http://nbviewer.jupyter.org/github/pnavaro/big-data/blob/master/03.ParallelComputation.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parallel Computation\n",
    "\n",
    "## Parallel computers\n",
    "- Multiprocessor/multicore: several processors work on data stored in shared memory\n",
    "- Cluster: several processor/memory units work together by exchanging data over a network\n",
    "- Co-processor: a general-purpose processor delegates specific tasks to a special-purpose processor (GPU, Xeon Phi,...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel Programming\n",
    "- Decomposition of the complete task into independent subtasks and the data flow between them.\n",
    "- Distribution of the subtasks over the processors minimizing the total execution time.\n",
    "- For clusters: distribution of the data over the nodes minimizing the communication time.\n",
    "- For multiprocessors: optimization of the memory access patterns minimizing waiting times.\n",
    "- Synchronization of the individual processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import sleep\n",
    "def f(x):\n",
    "    sleep(1)\n",
    "    return x*x\n",
    "L = list(range(8))\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 897 µs, sys: 1.17 ms, total: 2.07 ms\n",
      "Wall time: 8.02 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sum([f(x) for x in L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 907 µs, sys: 1.32 ms, total: 2.23 ms\n",
      "Wall time: 8.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sum(map(f,L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiprocessing \n",
    "\n",
    "<p>\n",
    "<font color=red> This first part with multiprocessing does not work\n",
    "    on Windows </font>\n",
    "    </p>\n",
    "\n",
    "The multiprocessing allows the programmer to fully leverage multiple processors.\n",
    "- The Pool object parallelizes the execution of a function across multiple input values.\n",
    "- The if __name__ == '__main__' part is necessary.\n",
    "- The multiprocessing Pool class provides a map function. Partition and distribute input to a user-specified function in pool of worker processes is automatic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "CPU times: user 14.1 ms, sys: 25.7 ms, total: 39.8 ms\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from multiprocessing import Pool\n",
    "\n",
    "if __name__ == '__main__': # Executed only on main process.\n",
    "    with Pool() as p:\n",
    "        print(sum(p.map(f, L))) # Apply f on L sequence and sum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Pool() launches one slave process per physical processor on the computer. \n",
    "- pool.map(...) divides the input list into chunks and puts the tasks (function + chunk) on a queue.\n",
    "- Each slave process takes a task (function + a chunk of data), runs map(function, chunk), and puts the result on a result list.\n",
    "- pool.map on the master process waits until all tasks are handled and returns the concatenation of the result lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 3.1\n",
    "\n",
    "- Use `paragraph` function module from `lorem` to create a text\n",
    "- Create a list of words from it\n",
    "- Use `map` function from `multiprocessing.Pool` to compute each word length\n",
    "- Compare time with sequential version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3 6 7 4 5 2 4 3 5 10 5 11 8 4 5 7 4 6 5 5 4 7 5 11 10 7 7 4 11 7 8 6 7 7 7\n",
      "CPU times: user 3.37 ms, sys: 3.17 ms, total: 6.54 ms\n",
      "Wall time: 4.34 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from lorem import paragraph\n",
    "\n",
    "words_list = paragraph().lower().replace('.','').split()\n",
    "print(*map(len,words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3 6 7 4 5 2 4 3 5 10 5 11 8 4 5 7 4 6 5 5 4 7 5 11 10 7 7 4 11 7 8 6 7 7 7\n",
      "CPU times: user 11.6 ms, sys: 24.2 ms, total: 35.8 ms\n",
      "Wall time: 132 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from multiprocessing import Pool\n",
    "\n",
    "if __name__ == '__main__': # Executed only on main process.\n",
    "    with Pool() as p:\n",
    "        results = p.map(len, words_list)# Apply f on L sequence and sum\n",
    "\n",
    "print(*results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thread and Process: Differences\n",
    "\n",
    "- A Process is an instance of a running program. \n",
    "- Process may contain one or more threads, but a thread cannot contain a process.\n",
    "- Process has a self-contained execution environment. It has its own memory space. \n",
    "- Application running on your computer may be a set of cooperating processes.\n",
    "\n",
    "- A Thread is made of and exist within a Process; every process has at least one. \n",
    "- Multiple threads in a process share resources, which helps in efficient communication between threads.\n",
    "- Threads can be concurrent on a multi-core system, with every core executing the separate threads simultaneously.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Global Interpreter Lock (GIL)\n",
    "\n",
    "- The Python interpreter is not thread safe.\n",
    "- A few critical internal data structures may only be accessed by one thread at a time. Access to them is protected by the GIL.\n",
    "- Attempts at removing the GIL from Python have failed until now. The main difficulty is maintaining the C API for extension modules.\n",
    "- Multiprocessing avoids the GIL by having separate processes which each have an independent copy of the interpreter data structures.\n",
    "- The price to pay: serialization of tasks, arguments, and results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Futures\n",
    "\n",
    "The `concurrent.futures` module provides a high-level interface for asynchronously executing callables.\n",
    "\n",
    "\n",
    "\n",
    "The asynchronous execution can be performed with:\n",
    "- **threads**, using ThreadPoolExecutor, \n",
    "- separate **processes**, using ProcessPoolExecutor. \n",
    "Both implement the same interface, which is defined by the abstract Executor class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`concurrent.futures` does not work on windows. Windows users must install \n",
    "[loky](https://github.com/tomMoral/loky)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install loky  # Windows users will need to install loky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "CPU times: user 11.3 ms, sys: 21.6 ms, total: 32.9 ms\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "# from loky import ProcessPoolExecutor  # for Windows users\n",
    "e = ProcessPoolExecutor()\n",
    "\n",
    "results = sum(e.map(f, L))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "CPU times: user 4.54 ms, sys: 5.16 ms, total: 9.7 ms\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "e = ThreadPoolExecutor()\n",
    "\n",
    "results = sum(e.map(f, L))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 3.2\n",
    "\n",
    "Use `ProcessPoolExecutor` to compute each word length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 3.3\n",
    "\n",
    "Same as exercise 4 but use `ThreadPoolExecutor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Map\n",
    "\n",
    "This words version contains some improvements and print out the \n",
    "process number where the function is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess reading sample.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('adipisci', 1),\n",
       " ('adipisci', 1),\n",
       " ('adipisci', 1),\n",
       " ('adipisci', 1),\n",
       " ('adipisci', 1),\n",
       " ('adipisci', 1),\n",
       " ('adipisci', 1),\n",
       " ('aliquam', 1),\n",
       " ('aliquam', 1),\n",
       " ('aliquam', 1),\n",
       " ('aliquam', 1),\n",
       " ('aliquam', 1),\n",
       " ('aliquam', 1),\n",
       " ('aliquam', 1),\n",
       " ('aliquam', 1),\n",
       " ('aliquam', 1),\n",
       " ('aliquam', 1),\n",
       " ('aliquam', 1),\n",
       " ('aliquam', 1),\n",
       " ('aliquam', 1),\n",
       " ('aliquam', 1),\n",
       " ('amet', 1),\n",
       " ('amet', 1),\n",
       " ('amet', 1),\n",
       " ('amet', 1),\n",
       " ('amet', 1),\n",
       " ('amet', 1),\n",
       " ('amet', 1),\n",
       " ('amet', 1),\n",
       " ('amet', 1),\n",
       " ('amet', 1),\n",
       " ('amet', 1),\n",
       " ('amet', 1),\n",
       " ('amet', 1),\n",
       " ('amet', 1),\n",
       " ('consectetur', 1),\n",
       " ('consectetur', 1),\n",
       " ('consectetur', 1),\n",
       " ('consectetur', 1),\n",
       " ('consectetur', 1),\n",
       " ('dolor', 1),\n",
       " ('dolor', 1),\n",
       " ('dolor', 1),\n",
       " ('dolor', 1),\n",
       " ('dolor', 1),\n",
       " ('dolor', 1),\n",
       " ('dolor', 1),\n",
       " ('dolor', 1),\n",
       " ('dolor', 1),\n",
       " ('dolore', 1),\n",
       " ('dolore', 1),\n",
       " ('dolore', 1),\n",
       " ('dolore', 1),\n",
       " ('dolorem', 1),\n",
       " ('dolorem', 1),\n",
       " ('dolorem', 1),\n",
       " ('dolorem', 1),\n",
       " ('dolorem', 1),\n",
       " ('dolorem', 1),\n",
       " ('eius', 1),\n",
       " ('eius', 1),\n",
       " ('eius', 1),\n",
       " ('eius', 1),\n",
       " ('eius', 1),\n",
       " ('eius', 1),\n",
       " ('eius', 1),\n",
       " ('eius', 1),\n",
       " ('eius', 1),\n",
       " ('eius', 1),\n",
       " ('est', 1),\n",
       " ('est', 1),\n",
       " ('est', 1),\n",
       " ('est', 1),\n",
       " ('est', 1),\n",
       " ('est', 1),\n",
       " ('est', 1),\n",
       " ('etincidunt', 1),\n",
       " ('etincidunt', 1),\n",
       " ('etincidunt', 1),\n",
       " ('etincidunt', 1),\n",
       " ('etincidunt', 1),\n",
       " ('etincidunt', 1),\n",
       " ('etincidunt', 1),\n",
       " ('etincidunt', 1),\n",
       " ('etincidunt', 1),\n",
       " ('etincidunt', 1),\n",
       " ('etincidunt', 1),\n",
       " ('ipsum', 1),\n",
       " ('ipsum', 1),\n",
       " ('ipsum', 1),\n",
       " ('ipsum', 1),\n",
       " ('ipsum', 1),\n",
       " ('ipsum', 1),\n",
       " ('ipsum', 1),\n",
       " ('ipsum', 1),\n",
       " ('ipsum', 1),\n",
       " ('ipsum', 1),\n",
       " ('ipsum', 1),\n",
       " ('labore', 1),\n",
       " ('labore', 1),\n",
       " ('labore', 1),\n",
       " ('labore', 1),\n",
       " ('labore', 1),\n",
       " ('labore', 1),\n",
       " ('labore', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('magnam', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('modi', 1),\n",
       " ('neque', 1),\n",
       " ('neque', 1),\n",
       " ('neque', 1),\n",
       " ('neque', 1),\n",
       " ('neque', 1),\n",
       " ('neque', 1),\n",
       " ('non', 1),\n",
       " ('non', 1),\n",
       " ('non', 1),\n",
       " ('non', 1),\n",
       " ('non', 1),\n",
       " ('non', 1),\n",
       " ('non', 1),\n",
       " ('non', 1),\n",
       " ('non', 1),\n",
       " ('non', 1),\n",
       " ('non', 1),\n",
       " ('non', 1),\n",
       " ('non', 1),\n",
       " ('numquam', 1),\n",
       " ('numquam', 1),\n",
       " ('numquam', 1),\n",
       " ('numquam', 1),\n",
       " ('numquam', 1),\n",
       " ('numquam', 1),\n",
       " ('numquam', 1),\n",
       " ('numquam', 1),\n",
       " ('numquam', 1),\n",
       " ('numquam', 1),\n",
       " ('numquam', 1),\n",
       " ('numquam', 1),\n",
       " ('porro', 1),\n",
       " ('porro', 1),\n",
       " ('porro', 1),\n",
       " ('porro', 1),\n",
       " ('porro', 1),\n",
       " ('porro', 1),\n",
       " ('porro', 1),\n",
       " ('porro', 1),\n",
       " ('porro', 1),\n",
       " ('porro', 1),\n",
       " ('porro', 1),\n",
       " ('porro', 1),\n",
       " ('porro', 1),\n",
       " ('porro', 1),\n",
       " ('quaerat', 1),\n",
       " ('quaerat', 1),\n",
       " ('quaerat', 1),\n",
       " ('quaerat', 1),\n",
       " ('quaerat', 1),\n",
       " ('quaerat', 1),\n",
       " ('quaerat', 1),\n",
       " ('quaerat', 1),\n",
       " ('quaerat', 1),\n",
       " ('quaerat', 1),\n",
       " ('quaerat', 1),\n",
       " ('quaerat', 1),\n",
       " ('quiquia', 1),\n",
       " ('quiquia', 1),\n",
       " ('quiquia', 1),\n",
       " ('quiquia', 1),\n",
       " ('quiquia', 1),\n",
       " ('quiquia', 1),\n",
       " ('quiquia', 1),\n",
       " ('quiquia', 1),\n",
       " ('quiquia', 1),\n",
       " ('quiquia', 1),\n",
       " ('quiquia', 1),\n",
       " ('quiquia', 1),\n",
       " ('quisquam', 1),\n",
       " ('quisquam', 1),\n",
       " ('quisquam', 1),\n",
       " ('quisquam', 1),\n",
       " ('quisquam', 1),\n",
       " ('quisquam', 1),\n",
       " ('quisquam', 1),\n",
       " ('quisquam', 1),\n",
       " ('quisquam', 1),\n",
       " ('quisquam', 1),\n",
       " ('quisquam', 1),\n",
       " ('quisquam', 1),\n",
       " ('quisquam', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sed', 1),\n",
       " ('sit', 1),\n",
       " ('sit', 1),\n",
       " ('sit', 1),\n",
       " ('sit', 1),\n",
       " ('sit', 1),\n",
       " ('sit', 1),\n",
       " ('sit', 1),\n",
       " ('sit', 1),\n",
       " ('sit', 1),\n",
       " ('sit', 1),\n",
       " ('sit', 1),\n",
       " ('sit', 1),\n",
       " ('sit', 1),\n",
       " ('sit', 1),\n",
       " ('sit', 1),\n",
       " ('tempora', 1),\n",
       " ('tempora', 1),\n",
       " ('tempora', 1),\n",
       " ('tempora', 1),\n",
       " ('tempora', 1),\n",
       " ('tempora', 1),\n",
       " ('tempora', 1),\n",
       " ('tempora', 1),\n",
       " ('tempora', 1),\n",
       " ('tempora', 1),\n",
       " ('ut', 1),\n",
       " ('ut', 1),\n",
       " ('ut', 1),\n",
       " ('ut', 1),\n",
       " ('ut', 1),\n",
       " ('ut', 1),\n",
       " ('ut', 1),\n",
       " ('ut', 1),\n",
       " ('ut', 1),\n",
       " ('ut', 1),\n",
       " ('ut', 1),\n",
       " ('ut', 1),\n",
       " ('ut', 1),\n",
       " ('velit', 1),\n",
       " ('velit', 1),\n",
       " ('velit', 1),\n",
       " ('velit', 1),\n",
       " ('velit', 1),\n",
       " ('velit', 1),\n",
       " ('velit', 1),\n",
       " ('velit', 1),\n",
       " ('velit', 1),\n",
       " ('voluptatem', 1),\n",
       " ('voluptatem', 1),\n",
       " ('voluptatem', 1),\n",
       " ('voluptatem', 1),\n",
       " ('voluptatem', 1),\n",
       " ('voluptatem', 1),\n",
       " ('voluptatem', 1),\n",
       " ('voluptatem', 1),\n",
       " ('voluptatem', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import multiprocessing as mp  # Windows users should comment this line\n",
    "def words_mp(file):\n",
    "    \"\"\"\n",
    "    Check if file is utf8\n",
    "    Read a text file and return a sorted list of (word, 1) values.\n",
    "    \"\"\"\n",
    "    # Windows users should comment this line below\n",
    "    print(mp.current_process().name, 'reading', file)\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    output = []\n",
    "    try:\n",
    "        with open(file) as f:\n",
    "            for line in f:   \n",
    "                line = line.strip()\n",
    "                line = line.translate(translator)\n",
    "                for word in line.split():\n",
    "                    if word.isalpha():\n",
    "                        word = word.lower()\n",
    "                        output.append((word, 1))\n",
    "                        \n",
    "    except UnicodeDecodeError as err:\n",
    "        print(\"Some error occurred decoding file %s: %s\" % (file, err))\n",
    "                \n",
    "    output.sort()\n",
    "    return output\n",
    "\n",
    "words_mp('sample.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Partition\n",
    "Before parallel reduce operation, data must be aligned in a container. We create a function named `partition_mp` that stores the key/value pairs from `words_mp` into a `defaultdict` from collections module. Ouput is:\n",
    "[('word1', [1, 1]), ('word2', [1]), ('word3', [1, 1, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "def partition_mp(mapped_values):\n",
    "    \"\"\"\n",
    "        Organize the mapped values by their key.\n",
    "        Returns an unsorted sequence of tuples \n",
    "        with a key and a sequence of values.\n",
    "    \"\"\"\n",
    "    partitioned_data = collections.defaultdict(list)\n",
    "    for key, value in mapped_values:\n",
    "        partitioned_data[key].append(value)\n",
    "    return partitioned_data.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess reading sample.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_items([('adipisci', [1, 1, 1, 1, 1, 1, 1]), ('aliquam', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('amet', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('consectetur', [1, 1, 1, 1, 1]), ('dolor', [1, 1, 1, 1, 1, 1, 1, 1, 1]), ('dolore', [1, 1, 1, 1]), ('dolorem', [1, 1, 1, 1, 1, 1]), ('eius', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('est', [1, 1, 1, 1, 1, 1, 1]), ('etincidunt', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('ipsum', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('labore', [1, 1, 1, 1, 1, 1, 1]), ('magnam', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('modi', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('neque', [1, 1, 1, 1, 1, 1]), ('non', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('numquam', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('porro', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('quaerat', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('quiquia', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('quisquam', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('sed', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('sit', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('tempora', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('ut', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('velit', [1, 1, 1, 1, 1, 1, 1, 1, 1]), ('voluptatem', [1, 1, 1, 1, 1, 1, 1, 1, 1])])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_mp(words_mp('sample.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mp(item):\n",
    "    \"\"\"Convert the partitioned data for a word to a\n",
    "    tuple containing the word and the number of occurances.\n",
    "    \"\"\"\n",
    "    word, occurances = item\n",
    "    return (word, len(occurances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainProcess reading sample.txt\n",
      "('adipisci', 7)\n",
      "('aliquam', 14)\n",
      "('amet', 14)\n",
      "('consectetur', 5)\n",
      "('dolor', 9)\n",
      "('dolore', 4)\n",
      "('dolorem', 6)\n",
      "('eius', 10)\n",
      "('est', 7)\n",
      "('etincidunt', 11)\n",
      "('ipsum', 11)\n",
      "('labore', 7)\n",
      "('magnam', 20)\n",
      "('modi', 18)\n",
      "('neque', 6)\n",
      "('non', 13)\n",
      "('numquam', 12)\n",
      "('porro', 14)\n",
      "('quaerat', 12)\n",
      "('quiquia', 12)\n",
      "('quisquam', 13)\n",
      "('sed', 16)\n",
      "('sit', 15)\n",
      "('tempora', 10)\n",
      "('ut', 13)\n",
      "('velit', 9)\n",
      "('voluptatem', 9)\n"
     ]
    }
   ],
   "source": [
    "for occurences in partition_mp(words_mp('sample.txt')):\n",
    "    print(reduce_mp(occurences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 3.4\n",
    "\n",
    "Write a parallel program that uses the three functions above using `multiprocessing module`. It reads all the \"sample\\*.txt\" files. Some hints:\n",
    "- Map and reduce steps are parallel.\n",
    "- See how `itertools.chain(*mapped_values)` is used in notebook exercise 01.6.\n",
    "- Compare time between the notebook 01 version. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 3.5\n",
    "\n",
    "- Replace `multiprocessing` by `concurrent.futures` functions.\n",
    "- Try  `ProcessPoolExecutor` and `ThreadPoolExecutor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can use for your multi-processing computations both `multiprocessing.Pool` and  `concurrent.futures` object, which behaves more or less identically.\n",
    "\n",
    "However, today most library designers are coordinating around the  second interface, so it's wise to move over.\n",
    "\n",
    "`concurrent.futures.ProcessPoolExecutor` is suitable for simple parallelism across many files and you gain some speed boost. \n",
    "Describing each task as a function call helps use tools like map for parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase volume of data\n",
    "\n",
    "### Getting the data\n",
    "\n",
    "[The Latin Library](http://www.thelatinlibrary.com/) contains a huge collection of freely accessible Latin texts. We get links on the Latin Library's homepage ignoring some links that are not associated with a particular author.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, HTTPError\n",
    "\n",
    "base_url = \"http://www.thelatinlibrary.com/\"\n",
    "home_content = urlopen(base_url)\n",
    "soup = BeautifulSoup(home_content, \"lxml\")\n",
    "author_page_links = soup.find_all(\"a\")\n",
    "author_pages = [ap[\"href\"] for i, ap in enumerate(author_page_links) if i < 49]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of all links pointing to Latin texts. The Latin Library uses a special format which makes it easy to find the corresponding links: All of these links contain the name of the text author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_content = list()\n",
    "for ap in author_pages:\n",
    "    ap_content.append(urlopen(base_url + ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"ammianus/14.shtml\">Liber XIV</a>, <a href=\"ammianus/15.shtml\">Liber XV</a>, <a href=\"ammianus/16.shtml\">Liber XVI</a>, <a href=\"ammianus/17.shtml\">Liber XVII</a>, <a href=\"ammianus/18.shtml\">Liber XVIII</a>]\n"
     ]
    }
   ],
   "source": [
    "book_links = list()\n",
    "for path, content in zip(author_pages, ap_content):\n",
    "    author_name = path.split(\".\")[0]\n",
    "    ap_soup = BeautifulSoup(content, \"lxml\")\n",
    "    book_links += ([link for link in ap_soup.find_all(\"a\", {\"href\": True}) if author_name in link[\"href\"]])\n",
    "\n",
    "print(book_links[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content 100 of 100\r"
     ]
    }
   ],
   "source": [
    "texts = list()\n",
    "num_pages = 100\n",
    "\n",
    "for i, bl in enumerate(book_links[:num_pages]):\n",
    "    print(\"Getting content \" + str(i + 1) + \" of \" + str(num_pages), end=\"\\r\", flush=True)\n",
    "    try:\n",
    "        content = urlopen(base_url + bl[\"href\"]).read() \n",
    "        texts.append(content)\n",
    "    except HTTPError as err:\n",
    "        print(\"Unable to retrieve \" + bl[\"href\"] + \".\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the text at periods to convert it into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infamabat autem haec suspicio latinum domesticorum comitem et agilonem tribunum stabuli atque scudilonem scutariorum rectorem qui tunc ut dextris suis gestantes rem publicam colebantur\n",
      "CPU times: user 8 s, sys: 84.3 ms, total: 8.09 s\n",
      "Wall time: 8.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences = list()\n",
    "\n",
    "for text in texts:\n",
    "    print(\"Document \" + str(i + 1) + \" of \" + str(len(texts)), end=\"\\r\", flush=True)\n",
    "    textSoup = BeautifulSoup(text, \"lxml\")\n",
    "    paragraphs = textSoup.find_all(\"p\", attrs={\"class\":None})\n",
    "    prepared = (\"\".join([p.text.strip().lower() for p in paragraphs[1:-1]]))\n",
    "    for t in prepared.split(\".\"):\n",
    "        part = \"\".join([c for c in t if c.isalpha() or c.isspace()])\n",
    "        sentences.append(part.strip())\n",
    "\n",
    "print(sentences[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.6\n",
    "\n",
    "Parallelize these last process using `concurrent.future`.\n",
    "Do not try to print out too much text, the notebook will raise an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Using Conditional Random Fields and Python for Latin word segmentation](https://medium.com/@felixmohr/using-python-and-conditional-random-fields-for-latin-word-segmentation-416ca7a9e513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
